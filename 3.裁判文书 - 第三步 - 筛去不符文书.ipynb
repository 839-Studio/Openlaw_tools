{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    "### 引入所有包,如果缺少某个包，包的名字附于之后\n",
    "import numpy as np\n",
    "# numpy\n",
    "\n",
    "import pandas as pd\n",
    "# pandas\n",
    "\n",
    "import requests\n",
    "# requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# BeautifulSoup\n",
    "\n",
    "import re\n",
    "# re\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "# fake-useragent\n",
    "\n",
    "import json\n",
    "# json\n",
    "\n",
    "import time\n",
    "# time\n",
    "\n",
    "import random\n",
    "# random\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# selenium\n",
    "\n",
    "from PIL import Image,ImageEnhance\n",
    "# PIL\n",
    "\n",
    "import hashlib\n",
    "# hashlib\n",
    "\n",
    "from collections import Counter\n",
    "# collections\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "# gensim \n",
    "\n",
    "import codecs, sys\n",
    "# codecs\n",
    "\n",
    "import os\n",
    "# os\n",
    "\n",
    "import shutil\n",
    "# shutil\n",
    "\n",
    "import jieba\n",
    "# jieba\n",
    "\n",
    "from pyhanlp import *\n",
    "# pyhanlp，注意hanlp需要java的工具\n",
    "\n",
    "import jpype\n",
    "# jpype\n",
    "\n",
    "import tensorflow as tf\n",
    "# tensorflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# sklearn\n",
    "\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "# pdfminer3k\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "## tk文件导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_table(root):\n",
    "    \"\"\"\n",
    "    return table\"选中的表格\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root.filename = filedialog.askopenfilename(filetypes=((\"xlsx\", \"*.xlsx\"),(\"xlsx\", \"*.xlsx\")))        \n",
    "        if \".xlsx\" in root.filename:\n",
    "            ### 该目录下有该文件\n",
    "            table = pd.read_excel(root.filename)\n",
    "            root.destroy()\n",
    "            return table\n",
    "    except Exception as e:\n",
    "        root.destroy()\n",
    "        print(\"导入错误\")\n",
    "\n",
    "def save_model(table):\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"以下为表格的预览:\")\n",
    "    print(table.head())\n",
    "    flag = input(\"是否需要保存该词频表？(输入Y/N):\")\n",
    "    try:\n",
    "        if flag == \"Y\":\n",
    "            save_file_name = input(\"请输入该词频表格的名称(不用加.xlsx):\")\n",
    "            save_file_name_xlsx = save_file_name + \".xlsx\"\n",
    "            table.to_excel(save_file_name_xlsx)\n",
    "            print(\"存储完毕\")\n",
    "        else:\n",
    "            print(\"未能存储\")\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class openlaw_filter:\n",
    "    def __init__(self,corpus):\n",
    "        \"\"\"\n",
    "        Param corpus:预处理的文本\n",
    "        \"\"\"\n",
    "        self.pattern_list = [] # 初始化规则\n",
    "        self.corpus = corpus # 初始化预处理文本\n",
    "\n",
    "    def generate_patterns(self,*args):\n",
    "        \"\"\"\n",
    "        Param *args:需要添加的规则\n",
    "        return pattern_list:规则表\n",
    "        \"\"\"\n",
    "        self.pattern_list = []\n",
    "        for item in args[0]:\n",
    "            pattern_ = re.compile(item)\n",
    "            self.pattern_list.append(pattern_)\n",
    "        return self.pattern_list\n",
    "    \n",
    "    def basic_mapping(self,single_document):\n",
    "        \"\"\"\n",
    "        Param single_document:文件的单个映射\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for pattern in self.pattern_list:\n",
    "                if re.search(pattern,single_document):\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "        except Exception as e:\n",
    "            return False\n",
    "        \n",
    "    def regex_filter(self,*args):\n",
    "        \"\"\"\n",
    "        Param *args:需要添加的规则\n",
    "        \"\"\"\n",
    "        list_args = []\n",
    "        for item in args:\n",
    "            list_args.append(item)\n",
    "        regex_list = self.generate_patterns(list_args)\n",
    "        result = list(map(self.basic_mapping,self.corpus))\n",
    "        return result\n",
    "        \n",
    "    def find_difference_set(self,single_para,stopwords_clean):\n",
    "        \"\"\"\n",
    "        将stopwords和每一段文本取差集，清洗数据\n",
    "        param single_para:没清洗文本集中的每一段数据\n",
    "        return list_clean:每一段清洗好的文本\n",
    "        \"\"\"\n",
    "        list_clean = set(single_para).difference(set(stopwords_clean))\n",
    "        return list_clean\n",
    "        \n",
    "    def data_prepare(self,corpus_clean):\n",
    "        \"\"\"\n",
    "        把数据清理干净\n",
    "        param text_list:没清洗过的文本列表\n",
    "        return list_clean:清洗过的文本列表\n",
    "        \"\"\"\n",
    "        table_segments_list = list(map(lambda x:jieba.lcut(x),corpus_clean))\n",
    "        stopwords = list(map(lambda x:x.strip(\"\\n\"),codecs.open('stopwords.txt', 'r', 'utf-8').readlines()))\n",
    "        stopwords_clean = list(map(lambda x:x.strip(\"\\r\"),stopwords))\n",
    "        list_clean = list(map(self.find_difference_set,table_segments_list,stopwords_clean))\n",
    "        return list_clean\n",
    "        \n",
    "    def tfidf(self,list_clean):\n",
    "        \"\"\" \n",
    "        产生tf-idf的模型\n",
    "        param self.clean_text:清洗过的文本列表\n",
    "        return corpus_tfidf:tf-idf模型\n",
    "        \"\"\"\n",
    "        texts = list_clean\n",
    "        # 建立词典\n",
    "        dictionary = corpora.Dictionary(list_clean)\n",
    "        \n",
    "        # 存档词典\n",
    "        dictionary.save(\"dict_v1.dict\")\n",
    "        \n",
    "        # 建立词袋模型\n",
    "        corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "        \n",
    "        # 建立tf-idf模型\n",
    "        tfidf = models.TfidfModel(corpus)\n",
    "        \n",
    "        # 将词袋模型，转换为tf-idf模型\n",
    "        corpus_tfidf = tfidf[corpus]\n",
    "        return corpus_tfidf\n",
    "    \n",
    "    def find_similar_result(self,corpus_tfidf,article_arg,results):\n",
    "        \"\"\"\n",
    "        使用tf-idf模型，计算文本间的余弦相似，得到结果\n",
    "        param corpus_tfidf:tf-idf模型\n",
    "        param target_article_arg:目标文本的下标号\n",
    "        return list_final_similarities:最终的相似结果\n",
    "        \"\"\"\n",
    "        # 创建索引\n",
    "        index = similarities.MatrixSimilarity(corpus_tfidf)\n",
    "        list_final_similarities = []\n",
    "\n",
    "        # 查找最相似的十个判决结果,以第一个文本为例\n",
    "        sims = index[corpus_tfidf[article_arg]]\n",
    "        args = np.argsort(sims)[::-1]\n",
    "        sims.sort()\n",
    "        true_sims = sims[::-1]\n",
    "\n",
    "        final_args = []\n",
    "        final_args.extend(args)\n",
    "        for item in list(args):\n",
    "            list_final_similarities.append(results[item])\n",
    "        return list_final_similarities,true_sims,args\n",
    "    \n",
    "    def replace_none(self,elem):\n",
    "        if elem == None:\n",
    "            elem = \"None\"\n",
    "        return elem\n",
    "    \n",
    "    def cosine_similarity_filter(self,corpus_seq):\n",
    "        results = list(map(self.replace_none,self.corpus.dropna()))\n",
    "        list_clean = self.data_prepare(results)\n",
    "        corpus_tfidf = self.tfidf(list_clean)\n",
    "        result = self.find_similar_result(corpus_tfidf,corpus_seq,results)\n",
    "        return result\n",
    "        \n",
    "def run_regex_filter(table_final,*args):\n",
    "    filter_ = openlaw_filter(table_final[\"法院意见\"])\n",
    "    results = filter_.regex_filter(*args)\n",
    "    return results\n",
    "    \n",
    "def run_cosine_filter(table_filter,corpus_seq):\n",
    "    filter_ = openlaw_filter(table_filter[\"判决结果\"])\n",
    "    results,sims,args = filter_.cosine_similarity_filter(corpus_seq)\n",
    "    results = pd.Series(results)\n",
    "    sims = pd.Series(sims)\n",
    "    args = pd.Series(args)\n",
    "    table_result = pd.DataFrame([sims,args]).T\n",
    "    table_result[\"content\"] = results\n",
    "    table_result.columns = [\"相似度\",\"文本序号\",\"判决结果内容\"]\n",
    "    return table_result\n",
    "\n",
    "def regex_filter_of_table(*args):\n",
    "    root = Tk() # 实例化TKinter窗口\n",
    "    root.withdraw() # 隐藏TKinter窗口\n",
    "    table_final = import_table(root)\n",
    "\n",
    "    results = run_regex_filter(table_final,*args)\n",
    "    table_final[\"符合要求的案件\"] = results\n",
    "    table_regex_filter = table_final[table_final[\"符合要求的案件\"] == True]\n",
    "    return table_regex_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入需要匹配的正则表达式:夫妻债务\n",
      "请问还要输入另一个正则表达式吗?(输入Y/N):Y\n",
      "请输入需要匹配的正则表达式:共同债务\n",
      "请问还要输入另一个正则表达式吗?(输入Y/N):N\n",
      "-------------------------------------------\n",
      "以下为表格的预览:\n",
      "                                  标题               案号 案件类型 庭审程序      案由 文书类型  \\\n",
      "0  上诉人官建坤与被上诉人蔡秀英及张兰英民间借贷纠纷一案再审民事判决书    （2018）川10民再3号   民事   再审  民间借贷纠纷  判决书   \n",
      "1               胡祝荣、刘汉雄民间借贷纠纷再审民事判决书  （2018）鄂1222民再1号   民事   再审  民间借贷纠纷  判决书   \n",
      "2               胡宇新、魏文祥民间借贷纠纷再审民事判决书   （2018）津01民再15号   民事   再审  民间借贷纠纷  判决书   \n",
      "4                张薇、何红军民间借贷纠纷再审民事判决书   （2018）川13民再31号   民事   再审  民间借贷纠纷  判决书   \n",
      "7               陈海宏、於艳娜民间借贷纠纷再审民事判决书    （2018）浙09民再7号   民事   再审  民间借贷纠纷  判决书   \n",
      "\n",
      "             法院         判决日期   原告       被告   ...   法院意见2  \\\n",
      "0  四川省内江市中级人民法院  2018年05月03日  官建坤  蔡秀英、张兰英   ...     NaN   \n",
      "1       通城县人民法院  2018年03月21日  胡祝荣  刘汉雄、陈仲华   ...     NaN   \n",
      "2   天津市第一中级人民法院  2018年03月22日  胡宇新  魏文祥、雷若寒   ...     NaN   \n",
      "4  四川省南充市中级人民法院  2018年08月03日   张薇  何红军、余宗军   ...     NaN   \n",
      "7  浙江省舟山市中级人民法院  2018年06月25日  陈海宏   於艳娜、李艳   ...     NaN   \n",
      "\n",
      "                                                判决结果 判决结果2  \\\n",
      "0  依照《最高人民法院关于审理涉及夫妻债务纠纷案件适用法律有关问题的解释》第三条、《中华人民共和...   NaN   \n",
      "1  依照《中华人民共和国民事诉讼法》第一百四十四条、第二百条第（六）项、第（九）项、第二百零七条...   NaN   \n",
      "2  依照最高人民法院《关于审理涉及夫妻债务纠纷案件适用法律有关问题的解释》第三条、《中华人民共和...   NaN   \n",
      "4  依照《中华人民共和国民事诉讼法》第一百七十条第一款第（二）项、《最高人民法院关于适用《中华人...   NaN   \n",
      "7  依据《最高人民法院关于审理涉及夫妻债务纠纷案件适用法律有关问题的解释》第二条，《中华人民共和...   NaN   \n",
      "\n",
      "                                                庭后告知 庭后告知2  \\\n",
      "0                                          本判决为终审判决。   NaN   \n",
      "1  如不服本判决，可在本判决书送达之日起十五日内，向本院递交上诉状及副本共三份，上诉于湖北省咸宁...   NaN   \n",
      "2                                          本判决为终审判决。   NaN   \n",
      "4                                          本判决为终审判决。   NaN   \n",
      "7                                          本判决为终审判决。   NaN   \n",
      "\n",
      "                                                结尾  结尾2  \\\n",
      "0             审判长王璐、审判员李小勇、审判员娄伟光、二〇一八年五月三日、书记员邹晓蕾  NaN   \n",
      "1         审判长何雅俐、审判员褚毅君、人民陪审员熊诗国、二〇一八年三月二十一日、书记员卢群  NaN   \n",
      "2          审判长赵会平、审判员李强、代理审判员祁洁、二〇一八年三月二十二日、书记员马伟杰  NaN   \n",
      "4            审判长任勇旗、审判员邹宏辉、审判员鲜代秋、二〇一八年八月三日、书记员朱月红  NaN   \n",
      "7  审判长周红兵、审判员周敏虎、审判员张娜、二〇一八年六月二十五日、法官助理陆朦璐、代书记员房晓娇  NaN   \n",
      "\n",
      "                                                  附录  附录2 符合要求的案件  \n",
      "0                                                NaN  NaN    True  \n",
      "1  附:相关法律、法规条文、《中华人民共和国民事诉讼法》、第一百四十四条被告经传票传唤，无正当理...  NaN    True  \n",
      "2  附:本裁判文书所依据法律规定的具体条文:、1、最高人民法院《关于审理涉及夫妻债务纠纷案件适用...  NaN    True  \n",
      "4                                                NaN  NaN    True  \n",
      "7                                                NaN  NaN    True  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "是否需要保存该词频表？(输入Y/N):y\n"
     ]
    }
   ],
   "source": [
    "## 如果要调用正则表达式筛选器，请在参数部分输入需要查找的参数\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    flag_TF = True\n",
    "    list_regex = []\n",
    "    while flag_TF:\n",
    "        regex = input(\"请输入需要匹配的正则表达式:\")\n",
    "        list_regex.append(regex)\n",
    "        flag = input(\"请问还要输入另一个正则表达式吗?(输入Y/N):\")\n",
    "        if flag == \"Y\":\n",
    "            flag_TF = True\n",
    "        else:\n",
    "            flag_TF = False\n",
    "    table_regex_result = regex_filter_of_table(*list_regex) # 在这里修改！可以在这里添加结果\n",
    "    save_model(table_regex_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 请选择使用哪个表？（通过正则处理过的表一般叫做table_filter_regex）\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "excel_name = input(\"请选择使用表的表名:(不需要加入.xlsx):\")\n",
    "corpus_seq_num = int(input(\"请选择使用表中的哪个文本作为相似初始对象？（请输入文本序号）:\"))\n",
    "name_bash = excel_name + \".xlsx\"\n",
    "table_filter_regex = pd.read_excel(name_bash)\n",
    "table = run_cosine_filter(table_filter_regex,corpus_seq_num)\n",
    "seq = table[\"文本序号\"]\n",
    "table_cosine_filter = table_filter_regex.loc[seq]\n",
    "print(\"----------------------------------------------------------\")\n",
    "save_to_excel_flag = input(\"是否要将其存成excel表格:(输入大写的Y或N):\")\n",
    "excel_name = input(\"请输入该excel表格的名字:\")\n",
    "if save_to_excel_flag == \"Y\":\n",
    "    name_bash = excel_name + \".xlsx\"\n",
    "    table_filter_regex.to_excel(name_bash)\n",
    "elif save_to_excel_flag == \"N\":\n",
    "    print(\"未有存储\")\n",
    "else:\n",
    "    print(\"输入错误\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"下列是与第\" + str(corpus_seq_num) + \"份文书有着相似判决结果的\" + str(len(table_cosine_filter)) + \"份文书预览\")\n",
    "table_cosine_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
