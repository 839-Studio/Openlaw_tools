{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第一模块(导入包模块：必须运行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 引入所有包,如果缺少某个包，包的名字附于之后\n",
    "import numpy as np\n",
    "# numpy\n",
    "\n",
    "import pandas as pd\n",
    "# pandas\n",
    "\n",
    "import requests\n",
    "# requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# BeautifulSoup\n",
    "\n",
    "import re\n",
    "# re\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "# fake-useragent\n",
    "\n",
    "import json\n",
    "# json\n",
    "\n",
    "import time\n",
    "# time\n",
    "\n",
    "import random\n",
    "# random\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# selenium\n",
    "\n",
    "from PIL import Image,ImageEnhance\n",
    "# PIL\n",
    "\n",
    "import hashlib\n",
    "# hashlib\n",
    "\n",
    "from collections import Counter\n",
    "# collections\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "# gensim \n",
    "\n",
    "import codecs, sys\n",
    "# codecs\n",
    "\n",
    "import os\n",
    "# os\n",
    "\n",
    "import time\n",
    "#time\n",
    "\n",
    "import shutil\n",
    "# shutil\n",
    "\n",
    "import jieba\n",
    "# jieba\n",
    "\n",
    "from pyhanlp import *\n",
    "# pyhanlp，注意hanlp需要java的工具\n",
    "\n",
    "import jpype\n",
    "# jpype\n",
    "\n",
    "import tensorflow as tf\n",
    "# tensorflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# sklearn\n",
    "\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "# pdfminer3k\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "# tk文件导入模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第二模块(文件处理模块：必须运行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_table(root):\n",
    "    \"\"\"\n",
    "    return table\"选中的表格\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root.filename = filedialog.askopenfilename(filetypes=((\"xlsx\", \"*.xlsx\"),(\"xlsx\", \"*.xlsx\")))        \n",
    "        if \".xlsx\" in root.filename:\n",
    "            ### 该目录下有该文件\n",
    "            table = pd.read_excel(root.filename)\n",
    "            root.destroy()\n",
    "            return table\n",
    "    except Exception as e:\n",
    "        root.destroy()\n",
    "        print(\"导入错误\")\n",
    "        \n",
    "def remote_select():\n",
    "    print(\"以下文件可以调用，需要分析哪个文件？\")\n",
    "    print(\"-------------------------------------\")\n",
    "    index = 0\n",
    "    list_item_temp = []\n",
    "    for item in os.listdir():\n",
    "        if \".xlsx\" in item:\n",
    "            index += 1\n",
    "            print(\"[\" + str(index) + \"] \" + item)\n",
    "            list_item_temp.append(item)\n",
    "    try:\n",
    "        bash_pos = \"/Users/dfuser/Desktop/目标文书目录/\"\n",
    "        file_code = int(input(\"需要导入哪个文件？(输入[]中的序号)\"))\n",
    "        final_pos = bash_pos + str(list_item_temp[file_code-1])\n",
    "        table_ = pd.read_excel(final_pos)\n",
    "        return table_\n",
    "        print(\"表格导入成功，以下是表格预览\")\n",
    "        print(\"----------------------------\")\n",
    "    except Exception as e:\n",
    "        print(\"导入错误\")\n",
    "\n",
    "def save_model_table1(table):\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"以下为表格的预览:\")\n",
    "    print(table.head())\n",
    "    flag = input(\"是否需要保存该摘要表？(输入Y/N):\")\n",
    "    try:\n",
    "        if flag == \"Y\":\n",
    "            save_file_name = input(\"请输入该分类表的名称(表1:主题 - 关键词表)(不用加.xlsx):\")\n",
    "            save_file_name_xlsx = save_file_name + \".xlsx\"\n",
    "            table.to_excel(save_file_name_xlsx)\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "def save_model_table2(table):\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"以下为表格的预览:\")\n",
    "    print(table.head())\n",
    "    flag = input(\"是否需要保存该摘要表？(输入Y/N):\")\n",
    "    try:\n",
    "        if flag == \"Y\":\n",
    "            save_file_name = input(\"请输入该分类表的名称(表2：各个文本对应的主题表)(不用加.xlsx):\")\n",
    "            save_file_name_xlsx = save_file_name + \".xlsx\"\n",
    "            table.to_excel(save_file_name_xlsx)\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 第三模块(LDA分类主逻辑)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(single_para,stopwords_clean):\n",
    "    \"\"\"\n",
    "    将stopwords和每一段文本取差集，清洗数据\n",
    "    param single_para:没清洗文本集中的每一段数据\n",
    "    return list_clean:每一段清洗好的文本\n",
    "    \"\"\"\n",
    "    list_clean = set(single_para).difference(set(stopwords_clean))\n",
    "    return list_clean\n",
    "\n",
    "def data_prepare(corpus):\n",
    "    \"\"\"\n",
    "    把数据清理干净\n",
    "    param text_list:没清洗过的文本列表\n",
    "    return list_clean:清洗过的文本列表\n",
    "    \"\"\"\n",
    "    def segments(x):\n",
    "        try:\n",
    "            return jieba.lcut(x)\n",
    "        except Exception as e:\n",
    "            return \"None\"\n",
    "    \n",
    "    table_segments_list = list(map(segments,corpus))\n",
    "    stopwords = list(map(lambda x:x.strip(\"\\n\"),codecs.open('stopwords.txt', 'r', 'utf-8').readlines()))\n",
    "    stopwords_clean = list(map(lambda x:x.strip(\"\\r\"),stopwords))\n",
    "    list_clean = list(map(clean,table_segments_list,stopwords_clean))\n",
    "    return list_clean\n",
    "\n",
    "def tfidf(clean_text):\n",
    "    \"\"\" \n",
    "    产生tf-idf的模型\n",
    "    param clean_text:清洗过的文本列表\n",
    "    return corpus_tfidf:tf-idf模型\n",
    "    \"\"\"\n",
    "    # 建立词典\n",
    "    dictionary = corpora.Dictionary(clean_text)\n",
    "\n",
    "    # 存档词典\n",
    "    dictionary.save('dict_v1.dict')\n",
    "\n",
    "    # 建立词袋模型\n",
    "    corpus = [dictionary.doc2bow(text) for text in clean_text]\n",
    "\n",
    "    # 建立tf-idf模型\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "    # 将词袋模型，转换为tf-idf模型\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    return corpus_tfidf\n",
    "\n",
    "# https://github.com/baidu/Familia/wiki\n",
    "def lda(lda_model,corpus_tfidf,table_original_texts,num_topics):\n",
    "    \"\"\"\n",
    "    使用lda算法进行分类\n",
    "    param corpus_tfidf:tf-idf模型\n",
    "    param table_original_texts:原始文本的列表\n",
    "    param num_topics:分类多少个主题\n",
    "    return table_keyword_classfication:关键词和关键词的分类表\n",
    "    return table_originaltext_classfication:原文文档和关键词的分类表\n",
    "    \"\"\"\n",
    "    # 关键词抽取 - 以及关键词属于哪一类\n",
    "    top_words_per_topic = []\n",
    "    for t in range(lda_model.num_topics):\n",
    "        top_words_per_topic.extend([(t, ) + x for x in lda_model.show_topic(t, topn = 10)])\n",
    "    table_keyword_classfication = pd.DataFrame(top_words_per_topic)\n",
    "    #table_keyword_classfication.to_excel(\"keyword_classification_words.xlsx\")\n",
    "    \n",
    "    # 原始文章的归类\n",
    "    list_classification_f = []\n",
    "    for x in [item for item in lda_model.get_document_topics(corpus_tfidf)]:\n",
    "        list_possibility = list(map(lambda x:x[1],x))\n",
    "        list_classification = list(map(lambda x:x[0],x))\n",
    "        list_possibility_index = list_possibility.index(max(list_possibility))\n",
    "        result = list_classification[list_possibility_index]\n",
    "        list_classification_f.append(result)\n",
    "    table_original_text_classfication = pd.DataFrame([list(table_original_texts),list_classification_f]).T\n",
    "    return table_keyword_classfication,table_original_text_classfication\n",
    "\n",
    "def extract_something(pattern,elem):\n",
    "    try:\n",
    "        extract_infos = re.search(pattern,elem).group()\n",
    "        return extract_infos\n",
    "    except Exception as e:\n",
    "        return \"None\"\n",
    "    \n",
    "def run_lda_model(table,selected_column):\n",
    "    \"\"\"\n",
    "    运行上述框架\n",
    "    param table:导入的表格\n",
    "    return keyword_classfication:为每类预测主题下的关键词\n",
    "    return original_text_classfication:为每个文本所可能归为的类别\n",
    "    \"\"\"\n",
    "    corpus = table[selected_column]\n",
    "    if selected_column == \"判决结果\":\n",
    "        pattern_judgements = re.compile(\"判决如下:(.*?)。\")\n",
    "        corpus_judgement = list(map(extract_something,len(corpus) * [pattern_judgements],corpus))\n",
    "        clean_text = data_prepare(corpus_judgement)\n",
    "        corpus_tfidf = tfidf(clean_text)\n",
    "        dictionary = corpora.Dictionary(clean_text)\n",
    "        num_topics = input(\"请输入需要分类的主题数量:\")\n",
    "        lda_model = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=num_topics, iterations=500)\n",
    "        keyword_classfication,original_text_classfication = lda(lda_model,corpus_tfidf,corpus_judgement,num_topics) #产生这两个表\n",
    "    else:\n",
    "        clean_text = data_prepare(corpus)\n",
    "        corpus_tfidf = tfidf(clean_text)\n",
    "        dictionary = corpora.Dictionary(clean_text)\n",
    "        num_topics = input(\"请输入需要分类的主题数量:\")\n",
    "        lda_model = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=num_topics, iterations=500)\n",
    "    \n",
    "        keyword_classfication,original_text_classfication = lda(lda_model,corpus_tfidf,corpus,num_topics) #产生这两个表\n",
    "        ### original_text_classfication：为每句话所归为的类别\n",
    "        ### keyword_classfication：为每类主题下的关键词\n",
    "    \n",
    "    keyword_classfication.columns = [\"属于分类\",\"分类关键词\",\"Weight\"]\n",
    "    original_text_classfication.columns = [\"文本\",\"属于分类\"]\n",
    "    \n",
    "    return keyword_classfication,original_text_classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 控制部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是在本机上操作？还是远程操作？(1:本机操作,2:远程操作)2\n",
      "以下文件可以调用，需要分析哪个文件？\n",
      "-------------------------------------\n",
      "[1] 夫妻债务 - 原表.xlsx\n",
      "[2] 校园暴力 - 结构化重构.xlsx\n",
      "[3] 校园暴力事件 - 原表.xlsx\n",
      "[4] 正当防卫 - 原表.xlsx\n",
      "[5] .~zhaiwu_regex_filter.xlsx.xlsx\n",
      "[6] 职业打假人 - 原表.xlsx\n",
      "需要导入哪个文件？(输入[]中的序号)3\n",
      "表格中所有的列: Index(['标题', '案号', '案件类型', '庭审程序', '案由', '文书类型', '法院', '判决日期', '原告', '被告',\n",
      "       '第三人', '法官', '审判长', '审判员', '书记员', '头部', '头部2', '当事人', '当事人2', '庭审程序说明',\n",
      "       '庭审程序说明2', '庭审过程', '庭审过程2', '庭审过程3', '庭审过程4', '庭审过程5', '庭审过程6', '法院意见',\n",
      "       '法院意见2', '判决结果', '判决结果2', '庭后告知', '庭后告知2', '结尾', '结尾2', '附录', '附录2'],\n",
      "      dtype='object')\n",
      "请问需要分析哪一列的关键词词频？(输入关键词部分):判决结果\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1114 16:13:30.465000 4649653696 smart_open_lib.py:385] this function is deprecated, use smart_open.open instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      依照《中华人民共和国侵权责任法》第十八条、第三十九条，《最高人民法院关于审理人身损害赔偿案件...\n",
      "1      综上所述，依照《中华人民共和国侵权责任法》第四十条、《最高人民法院关于民事诉讼证据的若干规定...\n",
      "2      综上所述，依照《中华人民共和国侵权责任法》第六条第一款、第十六条、第二十二条、第三十九条、《...\n",
      "3      综上，依据《中华人民共和国侵权责任法》第六条、第十二条、二十二条、第三十二条、第三十九条，《...\n",
      "4      依照《中华人民共和国侵权责任法》第二条、第十五条第一款第（六）项、第十六条、第三十二条第一款...\n",
      "5      依照《中华人民共和国刑法》第二百三十四条第一款，第七十二条，第三十六条第一款，《中华人民共和...\n",
      "6      依据《中华人民共和国民事诉讼法》第一百四十四条，《中华人民共和国侵权责任法》第二条、第三条、...\n",
      "7      据此，依照《中华人民共和国侵权责任法》第十六条、第三十二条、第三十九条，《关于审理人身损害赔...\n",
      "8      《中华人民共和国侵权法》第九条、第三十二条、第三十九条、《最高人民法院关于审理人身损害赔偿案...\n",
      "9      综上所述，《中华人民共和国侵权责任法》第八条、第十六条、第二十二条、第三十二条之规定判决如下...\n",
      "10     综上所述，《中华人民共和国侵权责任法》第八条、第十六条、第二十二条、第三十二条之规定判决如下...\n",
      "11     综上，根据《中华人民共和国侵权责任法》第六条、第三十九条之规定，判决如下:、一、被告邹某、王...\n",
      "12     根据被告人的犯罪事实、性质、情节及对社会的危害程度，依照《中华人民共和国刑法》第三百一十三条...\n",
      "13     依照《中华人民共和国侵权责任法》第八条、第十六条、第三十二条、《中华人民共和国民事诉讼法》第...\n",
      "14     综上所述，依据《中华人民共和国民法通则》第五条、第七条、第一百零一条之规定，判决如下:、驳回...\n",
      "15     依照《中华人民共和国行政诉讼法》第六十九条的规定，判决如下:、驳回原告李某甲的全部诉讼请求。...\n",
      "16     综上，依照《中华人民共和国侵权责任法》第三条、第六条、第十六条、第三十九条的规定，判决如下:...\n",
      "17     为此，依照《中华人民共和国侵权责任法》第十六条、第二十二条、第二十六条、第三十九条、第四十条...\n",
      "18     依照《中华人民共和国侵权责任法》第十六条、第三十九条的规定，判决如下:、一、被告胡某、柳某甲...\n",
      "19     综上所述，依照《中华人民共和国侵权责任法》第六条、第七条、第十六条、第四十条、《最高人民法院...\n",
      "20     综上，依据《中华人民共和国民事诉讼法》第六十四条、《中华人民共和国侵权责任法》第六条、第十二...\n",
      "21     综上，依据《中华人民共和国物权法》第三十七条，《中华人民共和国侵权责任法》第六条、第二十六条...\n",
      "22     据此，根据被告人陈某甲、张某乙的犯罪事实、性质、情节和社会危害程度，依照《中华人民共和国刑法...\n",
      "23     依照《中华人民共和国刑法》第二百七十七条第一款、第十八条第三款、第六十七条第三款之规定，判决...\n",
      "24     根据被告人的犯罪事实、性质、情节及社会危害程度，依照《中华人民共和国刑法》第二百九十一条之一...\n",
      "25                                                   NaN\n",
      "26     依照《中华人民共和国侵权责任法》第二条、第三条、第四条第一款、第六条第一款、第十六条，《最高...\n",
      "27     综上，依照《中华人民共和国侵权责任法》第二条、第六条、第十六条、第二十六条，《最高人民法院关...\n",
      "28     综上所述，依照《中华人民共和国侵权责任法》第六条、第十六条、第三十二条、第三十九条、《最高人...\n",
      "29     根据被告人的犯罪事实、犯罪性质、情节以及对社会的危害程度，依照《中华人民共和国刑法》第二百六...\n",
      "                             ...                        \n",
      "331    综上所述，为严肃国法，打击犯罪，保护公民人身权利，整顿金融市场秩序，本院结合各被告人在本案的...\n",
      "332    综上，依照《中华人民共和国刑法》第二百九十四条、第二百七十四条、第二百六十六条、第二百九十三...\n",
      "333    根据本案犯罪事实、性质、情节以及对社会的危害程度，依照《中华人民共和国刑法》第二百三十八条第...\n",
      "334    据此，根据各被告人的犯罪情节、危害后果及悔罪表现，依照《中华人民共和国刑法》第二百三十八条第...\n",
      "335    案经本院审判委员会讨论决定，对被告人洪某某1，依照《中华人民共和国刑法》第二百二十六条第（二...\n",
      "336    为维护社会治安秩序，保护公民的生命健康权不受侵犯，依照《中华人民共和国刑法》第二百三十二条、...\n",
      "337    综上，依照《中华人民共和国刑法》第二百九十三条第一款第（一）项、第（二）项、第三百零三条第二...\n",
      "338    据此，本院为保护公民人身及财产权利不受侵犯，惩治犯罪，对于被告人闵建彬依照《中华人民共和国刑...\n",
      "339    依照《中华人民共和国民法通则法》第九十二条，《最高人民法院关于贯彻执行若干问题的意见（试行）...\n",
      "340    综上所述，依照《中华人民共和国侵权责任法》第十五条第（六）项、第十六条、第二十六条、第七十三...\n",
      "341    综上，依照《中华人民共和国行政诉讼法》第七十四条第二款第一项、第七十六条，《中华人民共和国国...\n",
      "342    综上，为严惩严重暴力犯罪行为，保护公民人身权利，案经院审判委员会讨论并做出决定，依照《中华人...\n",
      "343    综上，依照《中华人民共和国行政诉讼法》第六十九条的规定，判决如下:、驳回原告建昌县和尚房子乡...\n",
      "344    根据赵玉祥的犯罪事实、性质、情节及社会危害程度，依照《中华人民共和国刑法》第二百九十三条第一...\n",
      "345    综上，根据被告人犯罪的事实、犯罪的性质、情节和对于社会的危害程度，对被告人周兴达依照《中华人...\n",
      "346    根据本案的犯罪事实、情节、社会危害程度，依照《中华人民共和国刑法》第二百三十八条第一款、第三...\n",
      "347    依照《中华人民共和国刑法》第二百六十四条，第六十七条第三款、第五十二条，第五十三条，第六十四...\n",
      "348    根据被告人犯罪的事实，犯罪的性质、情节和对于社会的危害程度，以及二附带民事诉讼原告人遭受财物...\n",
      "349    被告人李海建、李小泉系累犯，应对其从重处罚，被告人张晶有重大立功表现，可依法对其减轻处罚，十...\n",
      "350    故依照《中华人民共和国刑法》第二百九十二条第一款第二、第四项，第二百九十三条第二款第二项、第...\n",
      "351    据此，依照《中华人民共和国刑法》第三百八十二条第二款、第三款、第三百八十三条第一款第一项、第...\n",
      "352    依照《中华人民共和国刑法》第二百三十七条第二款、第三款，《最高人民法院、最高人民检察院、公安...\n",
      "353                                                  NaN\n",
      "354    依照《中华人民共和国刑法》第二百三十八条第一款、第二百七十四条、第二十三条、第二十七条、第六...\n",
      "355    据此，根据《中华人民共和国刑法》第二百七十四条、第二十五条第一款、第二十六条第一、四款、第五...\n",
      "356    依照《中华人民共和国刑法》第十二条、第二百七十四条、第二百七十一条、第三百八十二条、第三百八...\n",
      "357    综上，根据被告人许动余犯罪的事实、犯罪的性质、情节和对于社会的危害程度，依照《中华人民共和国...\n",
      "358    据此，依照《中华人民共和国刑法》第二百九十三条第一款第（三）项、第二百九十二条第一款第（四）...\n",
      "359    案经本院审判委员会讨论决定，依照《中华人民共和国刑法》第二百九十三条第一款第（一）项、第（二...\n",
      "360    据此，依照《中华人民共和国刑法》第十二条、1997《中华人民共和国刑法》第二百八十条、第六十...\n",
      "Name: 判决结果, Length: 361, dtype: object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "'NoneType' object has no attribute 'group'\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "'NoneType' object has no attribute 'group'\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "请输入需要分类的主题数量:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1114 16:13:36.920268 4649653696 ldamodel.py:934] too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "以下为表格的预览:\n",
      "   属于分类 分类关键词    Weight\n",
      "0     0     罪  0.007845\n",
      "1     0    一年  0.007526\n",
      "2     0     犯  0.007464\n",
      "3     0  有期徒刑  0.007354\n",
      "4     0    判处  0.007294\n",
      "是否需要保存该摘要表？(输入Y/N):N\n",
      "-------------------------------------------\n",
      "以下为表格的预览:\n",
      "                                                  文本 属于分类\n",
      "0  判决如下:、一、被告天津市滨海新区塘沽紫云中学于本判决生效之日起十日内给付原告刘学典、顾君丽...    3\n",
      "1                                判决如下:、驳回原告李某甲的诉讼请求。    4\n",
      "2  判决如下:、一、被告刘某2、安某于本判决生效之日起七日内赔偿原告何某1医疗费、护理费、交通费...    4\n",
      "3  判决如下:、一、被告于某2于本判决生效之日起七日内赔偿原告李某1心理咨询费一万四千四百元、精...    4\n",
      "4  判决如下:、一、被告王天然、董云红于本判决生效后十日内支付原告程映中经济损失2,578.83...    3\n",
      "是否需要保存该摘要表？(输入Y/N):N\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # ------ 导入函数开始\n",
    "    flag_input = int(input(\"你是在本机上操作？还是远程操作？(1:本机操作,2:远程操作)\"))\n",
    "    if flag_input == 1:\n",
    "        root = Tk() # 实例化TKinter窗口\n",
    "        root.withdraw() # 隐藏TKinter窗口\n",
    "        table_ready_to_eat = import_table(root)\n",
    "    elif flag_input == 2:\n",
    "        table_ready_to_eat = remote_select()\n",
    "    else:\n",
    "        logging.error(\"加载错误\")\n",
    "    # ------ 导入函数结束\n",
    "    \n",
    "    print(\"表格中所有的列:\",table_ready_to_eat.columns)\n",
    "    selected_column = input(\"请问需要分析哪一列的关键词词频？(输入关键词部分):\")\n",
    "    \n",
    "    keyword_classfication,original_text_classfication = run_lda_model(table_ready_to_eat,selected_column)\n",
    "    save_model_table1(keyword_classfication)\n",
    "    save_model_table2(original_text_classfication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text_classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
