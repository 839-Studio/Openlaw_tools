{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第一模块(导入包模块：必须运行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 引入所有包,如果缺少某个包，包的名字附于之后\n",
    "import numpy as np\n",
    "# numpy\n",
    "\n",
    "import pandas as pd\n",
    "# pandas\n",
    "\n",
    "import requests\n",
    "# requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# BeautifulSoup\n",
    "\n",
    "import re\n",
    "# re\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "# fake-useragent\n",
    "\n",
    "import json\n",
    "# json\n",
    "\n",
    "import time\n",
    "# time\n",
    "\n",
    "import random\n",
    "# random\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# selenium\n",
    "\n",
    "from PIL import Image,ImageEnhance\n",
    "# PIL\n",
    "\n",
    "import hashlib\n",
    "# hashlib\n",
    "\n",
    "from collections import Counter\n",
    "# collections\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "# gensim \n",
    "\n",
    "import codecs, sys\n",
    "# codecs\n",
    "\n",
    "import os\n",
    "# os\n",
    "\n",
    "import time\n",
    "#time\n",
    "\n",
    "import shutil\n",
    "# shutil\n",
    "\n",
    "import jieba\n",
    "# jieba\n",
    "\n",
    "from pyhanlp import *\n",
    "# pyhanlp，注意hanlp需要java的工具\n",
    "\n",
    "import jpype\n",
    "# jpype\n",
    "\n",
    "import tensorflow as tf\n",
    "# tensorflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# sklearn\n",
    "\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "# pdfminer3k\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "# tk文件导入模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第二模块(文件处理模块：必须运行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_table(root):\n",
    "    \"\"\"\n",
    "    return table\"选中的表格\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root.filename = filedialog.askopenfilename(filetypes=((\"xlsx\", \"*.xlsx\"),(\"xlsx\", \"*.xlsx\")))        \n",
    "        if \".xlsx\" in root.filename:\n",
    "            ### 该目录下有该文件\n",
    "            table = pd.read_excel(root.filename)\n",
    "            root.destroy()\n",
    "            return table\n",
    "    except Exception as e:\n",
    "        root.destroy()\n",
    "        print(\"导入错误\")\n",
    "\n",
    "def save_model(table):\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"以下为表格的预览:\")\n",
    "    print(table.head())\n",
    "    flag = input(\"是否需要保存该词频表？(输入Y/N):\")\n",
    "    try:\n",
    "        if flag == \"Y\":\n",
    "            save_file_name = input(\"请输入该词频表格的名称(不用加.xlsx):\")\n",
    "            save_file_name_xlsx = save_file_name + \".xlsx\"\n",
    "            table.to_excel(save_file_name_xlsx)\n",
    "            print(\"存储完毕\")\n",
    "        else:\n",
    "            print(\"未能存储\")\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第三模块(基于hanlp的绝对词频统计:必须运行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# 绝对词频统计\n",
    "pattern_word = re.compile(r\".*?\\\\\")\n",
    "pattern_nature = re.compile(r\"\\\\.*\")\n",
    "\n",
    "list_useful_words,list_natures = [],[]\n",
    "def segments(article,stopwords):\n",
    "    \"\"\"\n",
    "    param article:每篇文章\n",
    "    param stopwords:停用词列表\n",
    "    return list_articles:每篇文章的分词\n",
    "    \"\"\"\n",
    "    for item in HanLP.segment(article):\n",
    "        try:\n",
    "            item_word = ('{}\\{}'.format(item.word, item.nature))\n",
    "            word = re.search(pattern_word,item_word).group()\n",
    "            nature = re.search(pattern_nature,item_word).group()\n",
    "            word_clean = word.strip(\"\\\\\")\n",
    "            nature_clean = nature.strip(\"\\\\\")\n",
    "            if word_clean not in list_stopwords:\n",
    "                list_useful_words.append(word_clean)\n",
    "                list_natures.append(nature_clean)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return list_useful_words,list_natures\n",
    "\n",
    "def DF(list_useful_words,list_natures):\n",
    "    \"\"\"\n",
    "    param list_useful_words:清洗后得到的词表\n",
    "    param list_natures:清洗后词性的词性表\n",
    "    return table_test_3:\n",
    "    \"\"\"\n",
    "    table_test = pd.DataFrame([list_useful_words,list_natures]).T\n",
    "    table_test.columns = [\"word\",\"nature\"]\n",
    "    \n",
    "    ### 只提取名词和动词！！！！！！！！\n",
    "    table_test_2 = table_test[table_test[\"nature\"].isin([\"n\",\"v\"])]\n",
    "    table_test_3 = table_test_2.groupby(\"word\").count().sort_values([\"nature\"],ascending = [\"False\"])\n",
    "    return table_test_3\n",
    "\n",
    "def main_word_freqs(corpus,list_stopwords):\n",
    "    \"\"\"\n",
    "    param corpus:每个的文本\n",
    "    param list_stopwords:\n",
    "    return list_articles:每篇关键词的频率\n",
    "    \"\"\"\n",
    "    list_articles = []\n",
    "    for article in corpus[0:10]:\n",
    "        try:\n",
    "            list_useful_words,list_natures = segments(article,list_stopwords)\n",
    "            table = DF(list_useful_words,list_natures)\n",
    "            list_articles.append(table)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return list_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第四模块(控制部分!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "******************表格已经导入******************\n",
      "----------------------------------------------\n",
      "表格中所有的列: Index(['标题', '案号', '案件类型', '庭审程序', '案由', '文书类型', '法院', '判决日期', '原告', '被告',\n",
      "       '第三人', '法官', '审判长', '审判员', '书记员', '头部', '头部2', '当事人', '当事人2', '庭审程序说明',\n",
      "       '庭审程序说明2', '庭审过程', '庭审过程2', '庭审过程3', '庭审过程4', '庭审过程5', '庭审过程6', '法院意见',\n",
      "       '法院意见2', '判决结果', '判决结果2', '庭后告知', '庭后告知2', '结尾', '结尾2', '附录', '附录2'],\n",
      "      dtype='object')\n",
      "请问需要分析哪一列的关键词词频？(输入关键词部分):判决结果\n",
      "-------------------------------------------\n",
      "以下为表格的预览:\n",
      "      nature\n",
      "word        \n",
      "原告       205\n",
      "被告       173\n",
      "负担        99\n",
      "履行        76\n",
      "诉讼法       72\n",
      "是否需要保存该词频表？(输入Y/N):N\n",
      "未能存储\n"
     ]
    }
   ],
   "source": [
    "### 频率部分控制！\n",
    "### 懒得写__main__()了\n",
    "### table_filter_regex.xlsx\n",
    "\n",
    "def run_freqs(corpus,list_stopwords):\n",
    "    corpus = list(filter(lambda x:x!=None,corpus))\n",
    "    list_articles = main_word_freqs(corpus,list_stopwords)\n",
    "    table_result = pd.concat(list_articles).groupby(\"word\").sum().sort_values(\"nature\",ascending = False)\n",
    "    return table_result,list_articles\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    list_stopwords = []\n",
    "    with open(\"stopwords.txt\",\"r\",encoding = \"utf-8\") as f:\n",
    "        for word in f.readlines():\n",
    "            list_stopwords.append(word.strip(\"\\n\"))\n",
    "    root = Tk() # 实例化TKinter窗口\n",
    "    root.withdraw() # 隐藏TKinter窗口\n",
    "    table_ready_to_eat = import_table(root)\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"******************表格已经导入******************\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"表格中所有的列:\",table_ready_to_eat.columns)\n",
    "    selected_column = input(\"请问需要分析哪一列的关键词词频？(输入关键词部分):\")\n",
    "    corpus = table_ready_to_eat[selected_column]\n",
    "    table_word_freqs,list_articles = run_freqs(corpus,list_stopwords)\n",
    "    save_model(table_word_freqs)\n",
    "# table_filter_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
