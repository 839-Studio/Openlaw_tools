{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 引入所有包,如果缺少某个包，包的名字附于之后\n",
    "import numpy as np\n",
    "# numpy\n",
    "\n",
    "import pandas as pd\n",
    "# pandas\n",
    "\n",
    "import requests\n",
    "# requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# BeautifulSoup\n",
    "\n",
    "import re\n",
    "# re\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "# fake-useragent\n",
    "\n",
    "import json\n",
    "# json\n",
    "\n",
    "import time\n",
    "# time\n",
    "\n",
    "import random\n",
    "# random\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# selenium\n",
    "\n",
    "from PIL import Image,ImageEnhance\n",
    "# PIL\n",
    "\n",
    "import hashlib\n",
    "# hashlib\n",
    "\n",
    "from collections import Counter\n",
    "# collections\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "# gensim \n",
    "\n",
    "import codecs, sys\n",
    "# codecs\n",
    "\n",
    "import os\n",
    "# os\n",
    "\n",
    "import time\n",
    "#time\n",
    "\n",
    "import shutil\n",
    "# shutil\n",
    "\n",
    "import jieba\n",
    "# jieba\n",
    "\n",
    "from pyhanlp import *\n",
    "# pyhanlp，注意hanlp需要java的工具\n",
    "\n",
    "import jpype\n",
    "# jpype\n",
    "\n",
    "import tensorflow as tf\n",
    "# tensorflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# sklearn\n",
    "\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "# pdfminer3k\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "# tk文件导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_table(root):\n",
    "    \"\"\"\n",
    "    return table\"选中的表格\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root.filename = filedialog.askopenfilename(filetypes=((\"xlsx\", \"*.xlsx\"),(\"xlsx\", \"*.xlsx\")))        \n",
    "        if \".xlsx\" in root.filename:\n",
    "            ### 该目录下有该文件\n",
    "            table = pd.read_excel(root.filename)\n",
    "            root.destroy()\n",
    "            return table\n",
    "    except Exception as e:\n",
    "        root.destroy()\n",
    "        print(\"导入错误\")\n",
    "\n",
    "def save_model_table1(table):\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"以下为表格的预览:\")\n",
    "    print(table.head())\n",
    "    flag = input(\"是否需要保存该摘要表？(输入Y/N):\")\n",
    "    try:\n",
    "        if flag == \"Y\":\n",
    "            save_file_name = input(\"请输入该分类表的名称(表1:主题 - 关键词表)(不用加.xlsx):\")\n",
    "            save_file_name_xlsx = save_file_name + \".xlsx\"\n",
    "            table.to_excel(save_file_name_xlsx)\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "def save_model_table2(table):\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"以下为表格的预览:\")\n",
    "    print(table.head())\n",
    "    flag = input(\"是否需要保存该摘要表？(输入Y/N):\")\n",
    "    try:\n",
    "        if flag == \"Y\":\n",
    "            save_file_name = input(\"请输入该分类表的名称(表2：各个文本对应的主题表)(不用加.xlsx):\")\n",
    "            save_file_name_xlsx = save_file_name + \".xlsx\"\n",
    "            table.to_excel(save_file_name_xlsx)\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(single_para,stopwords_clean):\n",
    "    \"\"\"\n",
    "    将stopwords和每一段文本取差集，清洗数据\n",
    "    param single_para:没清洗文本集中的每一段数据\n",
    "    return list_clean:每一段清洗好的文本\n",
    "    \"\"\"\n",
    "    list_clean = set(single_para).difference(set(stopwords_clean))\n",
    "    return list_clean\n",
    "\n",
    "def data_prepare(corpus):\n",
    "    \"\"\"\n",
    "    把数据清理干净\n",
    "    param text_list:没清洗过的文本列表\n",
    "    return list_clean:清洗过的文本列表\n",
    "    \"\"\"\n",
    "    table_segments_list = list(map(lambda x:jieba.lcut(x),corpus))\n",
    "    stopwords = list(map(lambda x:x.strip(\"\\n\"),codecs.open('stopwords.txt', 'r', 'utf-8').readlines()))\n",
    "    stopwords_clean = list(map(lambda x:x.strip(\"\\r\"),stopwords))\n",
    "    list_clean = list(map(clean,table_segments_list,stopwords_clean))\n",
    "    return list_clean\n",
    "\n",
    "def tfidf(clean_text):\n",
    "    \"\"\" \n",
    "    产生tf-idf的模型\n",
    "    param clean_text:清洗过的文本列表\n",
    "    return corpus_tfidf:tf-idf模型\n",
    "    \"\"\"\n",
    "    # 建立词典\n",
    "    dictionary = corpora.Dictionary(clean_text)\n",
    "\n",
    "    # 存档词典\n",
    "    dictionary.save('dict_v1.dict')\n",
    "\n",
    "    # 建立词袋模型\n",
    "    corpus = [dictionary.doc2bow(text) for text in clean_text]\n",
    "\n",
    "    # 建立tf-idf模型\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "    # 将词袋模型，转换为tf-idf模型\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    return corpus_tfidf\n",
    "\n",
    "\n",
    "def lda(lda_model,corpus_tfidf,table_original_texts,num_topics):\n",
    "    \"\"\"\n",
    "    使用lda算法进行分类\n",
    "    param corpus_tfidf:tf-idf模型\n",
    "    param table_original_texts:原始文本的列表\n",
    "    param num_topics:分类多少个主题\n",
    "    return table_keyword_classfication:关键词和关键词的分类表\n",
    "    return table_originaltext_classfication:原文文档和关键词的分类表\n",
    "    \"\"\"\n",
    "    # 关键词抽取 - 以及关键词属于哪一类\n",
    "    top_words_per_topic = []\n",
    "    for t in range(lda_model.num_topics):\n",
    "        top_words_per_topic.extend([(t, ) + x for x in lda_model.show_topic(t, topn = 10)])\n",
    "    table_keyword_classfication = pd.DataFrame(top_words_per_topic)\n",
    "    #table_keyword_classfication.to_excel(\"keyword_classification_words.xlsx\")\n",
    "    \n",
    "    # 原始文章的归类\n",
    "    list_classification_f = []\n",
    "    for x in [item for item in lda_model.get_document_topics(corpus_tfidf)]:\n",
    "        list_possibility = list(map(lambda x:x[1],x))\n",
    "        list_classification = list(map(lambda x:x[0],x))\n",
    "        list_possibility_index = list_possibility.index(max(list_possibility))\n",
    "        result = list_classification[list_possibility_index]\n",
    "        list_classification_f.append(result)\n",
    "    table_original_text_classfication = pd.DataFrame([list(table_original_texts),list_classification_f]).T\n",
    "    return table_keyword_classfication,table_original_text_classfication\n",
    "\n",
    "def extract_something(pattern,elem):\n",
    "    try:\n",
    "        extract_infos = re.search(pattern_judgements,elem).group()\n",
    "        return extract_infos\n",
    "    except Exception as e:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    root = Tk() # 实例化TKinter窗口\n",
    "    root.withdraw() # 隐藏TKinter窗口\n",
    "    table_ready_to_eat = import_table(root)\n",
    "    \n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"******************表格已经导入******************\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"表格中所有的列:\",table_ready_to_eat.columns)\n",
    "    selected_column = input(\"请问需要分析哪一列的关键词词频？(输入关键词部分):\")\n",
    "    \n",
    "    corpus = table_ready_to_eat[selected_column]\n",
    "    pattern_judgements = re.compile(\"判决如下:(.*?)。\")\n",
    "    corpus_judgements = list(map(extract_something,len(corpus) * [pattern_judgements],corpus))\n",
    "    clean_text = data_prepare(corpus_judgements)\n",
    "    corpus_tfidf = tfidf(clean_text)\n",
    "    dictionary = corpora.Dictionary(clean_text)\n",
    "    num_topics = input(\"请输入需要分类的主题数量:\")\n",
    "    lda_model = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=num_topics, iterations=500)\n",
    "    \n",
    "    ### 此处可以得到两个表：\n",
    "    ### keyword_classfication：为每类主题下的关键词\n",
    "    ### original_text_classfication：为每句话所归为的类别\n",
    "    keyword_classfication,original_text_classfication = lda(lda_model,corpus_tfidf,corpus_judgements,num_topics) #产生这两个表\n",
    "    keyword_classfication.columns = [\"属于分类\",\"分类关键词\",\"Weight\"]\n",
    "    original_text_classfication.columns = [\"文本\",\"属于分类\"]\n",
    "    save_model_table1(keyword_classfication)\n",
    "    save_model_table2(original_text_classfication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
